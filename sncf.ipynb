{
    "cells": [
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "org.apache.spark.SparkContext@96a8de99"
                    }, 
                    "execution_count": 1
                }
            ], 
            "execution_count": 1, 
            "source": "sc"
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "2.1.0"
                    }, 
                    "execution_count": 2
                }
            ], 
            "execution_count": 2, 
            "source": "sc.version"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "positions-geographiques-des-stations-du-reseau-ratp"
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "name": "stdout", 
                    "text": "+-------+--------------------+--------------------+--------------------+------------------+------------------+----------+-----------+\n|stop_id|           stop_name|           stop_desc|               coord|          stop_lat|          stop_lon|code_INSEE|departement|\n+-------+--------------------+--------------------+--------------------+------------------+------------------+----------+-----------+\n|   2158|       Ach\u00e8res-Ville|Avenue de Conflan...|48.9700771763, 2....|48.970077176304514|2.0776181820083806|     78005|         78|\n|   2159|              Al\u00e9sia|Place Victor et H...|48.8280660197, 2....| 48.82806601968645| 2.326827420050836|     75114|         75|\n|   2172|            Concorde|Tuileries (jardin...|48.8654893909, 2....|  48.8654893908901| 2.321411789213801|     75108|         75|\n|   2174|          Convention|Vaugirard (337 ru...|48.8371369496, 2....| 48.83713694956265| 2.296396090155559|     75115|         75|\n|   2178|Courcelle-sur-Yvette|Rue Fernand Leger...|48.7007630181, 2....| 48.70076301806364| 2.099100527058702|     91272|         91|\n+-------+--------------------+--------------------+--------------------+------------------+------------------+----------+-----------+\nonly showing top 5 rows\n\n", 
                    "output_type": "stream"
                }
            ], 
            "execution_count": 4, 
            "source": "// The code was removed by DSX for sharing."
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Validatations"
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "name": "stdout", 
                    "text": "+----------+--------------+-------------+---------------+--------------------+-----------+---------------+-------+\n|      JOUR|CODE_STIF_TRNS|CODE_STIF_RES|CODE_STIF_ARRET|       LIBELLE_ARRET|ID_REFA_LDA|CATEGORIE_TITRE|NB_VALD|\n+----------+--------------+-------------+---------------+--------------------+-----------+---------------+-------+\n|2016-01-05|           100|          110|            762|SAINT-DENIS-PORTE...|      72285|      AMETHYSTE|  264.0|\n|2016-01-05|           100|          110|            766|       SAINT-GEORGES|      71366|            TST|  103.0|\n|2016-01-05|           100|          110|            768|       SAINT-JACQUES|      71041|            TST|  415.0|\n|2016-01-05|           100|          110|            769|        SAINT-LAZARE|      71370|      IMAGINE R|15406.0|\n|2016-01-05|           100|          110|            777|SAINT-PAUL (LE MA...|      71222|    AUTRE TITRE|   88.0|\n+----------+--------------+-------------+---------------+--------------------+-----------+---------------+-------+\nonly showing top 5 rows\n\n", 
                    "output_type": "stream"
                }, 
                {
                    "metadata": {}, 
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "Name: java.lang.InterruptedException\nMessage: null\nStackTrace:   at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1009)\n  at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1315)\n  at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:202)\n  at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:218)\n  at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:153)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1957)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:1971)\n  at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:954)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:381)\n  at org.apache.spark.rdd.RDD.collect(RDD.scala:953)\n  at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:275)\n  at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2371)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n  at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2765)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2370)\n  at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2377)\n  at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2405)\n  at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2404)\n  at org.apache.spark.sql.Dataset.withCallback(Dataset.scala:2778)\n  at org.apache.spark.sql.Dataset.count(Dataset.scala:2404)"
                    }, 
                    "execution_count": 48
                }
            ], 
            "execution_count": 48, 
            "source": "import org.apache.spark.sql.types.StructType\nimport org.apache.spark.sql.types._\n\nval customSchema = StructType(Array(\n    StructField(\"JOUR\", DateType, true),\n    StructField(\"CODE_STIF_TRNS\", StringType, true),\n    StructField(\"CODE_STIF_RES\", StringType, true),\n    StructField(\"CODE_STIF_ARRET\", StringType, true),\n    StructField(\"LIBELLE_ARRET\", StringType, true),\n    StructField(\"ID_REFA_LDA\", StringType, true),\n    StructField(\"CATEGORIE_TITRE\", StringType, true),\n    StructField(\"NB_VALD\", DoubleType, true)))\n\nval dfValidation = spark.\n    read.format(\"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\").\n    option(\"header\", \"true\").\n    schema(customSchema).\n    option(\"delimiter\",\";\").\n    option(\"mode\", \"DROPMALFORMED\").\n    load(\"swift://sncf.\" + name + \"/validations-sur-le-reseau-ferre-nombre-de-validations-par-jour-1er-semestre-2015.csv\")\ndfValidation.show(5)\nval nbrow = dfValidation.count"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }, 
            "source": "## 1. Total, min, max, \u00e9cart type de validations sur l'ensemble du r\u00e9seau"
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "name": "stdout", 
                    "text": "root\n |-- JOUR: date (nullable = true)\n |-- CODE_STIF_TRNS: string (nullable = true)\n |-- CODE_STIF_RES: string (nullable = true)\n |-- CODE_STIF_ARRET: string (nullable = true)\n |-- LIBELLE_ARRET: string (nullable = true)\n |-- ID_REFA_LDA: string (nullable = true)\n |-- CATEGORIE_TITRE: string (nullable = true)\n |-- NB_VALD: double (nullable = true)\n\n", 
                    "output_type": "stream"
                }
            ], 
            "execution_count": 15, 
            "source": "dfValidation.printSchema()"
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "name": "stdout", 
                    "text": "+---------------+---------+-------+\n|       col_name|data_type|comment|\n+---------------+---------+-------+\n|           JOUR|     date|   null|\n| CODE_STIF_TRNS|   string|   null|\n|  CODE_STIF_RES|   string|   null|\n|CODE_STIF_ARRET|   string|   null|\n|  LIBELLE_ARRET|   string|   null|\n|    ID_REFA_LDA|   string|   null|\n|CATEGORIE_TITRE|   string|   null|\n|        NB_VALD|   double|   null|\n+---------------+---------+-------+\n\n", 
                    "output_type": "stream"
                }
            ], 
            "execution_count": 23, 
            "source": "// Register the DataFrame as a global temporary view\n//dfValidation.createGlobalTempView(\"validation\")\nspark.sql(\"desc global_temp.validation\").show()\n"
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [], 
            "execution_count": 51, 
            "source": "import org.apache.spark.sql.functions._\nval result = spark.sql(\"select MAX(NB_VALD) as maxi from global_temp.validation\")\nresult.show()"
        }, 
        {
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "execution_count": null, 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Scala 2.11 with Spark 2.1", 
            "name": "scala-spark21", 
            "language": "scala"
        }, 
        "language_info": {
            "codemirror_mode": "text/x-scala", 
            "mimetype": "text/x-scala", 
            "pygments_lexer": "scala", 
            "version": "2.11.8", 
            "file_extension": ".scala", 
            "name": "scala"
        }
    }, 
    "nbformat_minor": 0, 
    "nbformat": 4
}